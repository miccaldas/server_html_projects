<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><title>scraper</title><link rel="stylesheet" href="/css/normalize.css"><link rel="stylesheet" href="/css/heti.min.css"><link rel="stylesheet" href="/css/hexo-theme-adoubi.css"><link rel="icon" href="/images/favicon.ico"><meta name="generator" content="Hexo 5.4.0"><link rel="alternate" href="/atom.xml" title="" type="application/atom+xml">
</head><body><div class="header"><a class="github-link" target="_blank" rel="noopener" href="https://notabug.org/micaldas"><img class="github-image" src="/images/Aquicon-Github-small.png"></a><a class="email-link" href="mailto:mclds@protonmail.com"><img class="email-image" src="/images/email-small.png"></a><a class="subscribe-link" href="/atom.xml"><img class="subscribe-image" src="/images/subscribe-small.png"></a></div><div class="content"><div class="post-item"></div><h2 class="post-title-wrapper"><p class="post-title">scraper</p></h2><div class="post-date"><time datetime="2021-08-10T08:34:18.000Z">2021-08-10</time></div><div class="post-content"><p>I just wrote a web-scraping tool based on <a target="_blank" rel="noopener" href="https://docs.scrapy.org/">Scrapy</a>.<br>There was a lot of new things that popped up during the build that I want to register while it’s still fresh in my mind.<br>My idea was this,</p>
<ul>
<li>check what are the steps necessary to have a spider up and running,  </li>
<li>Turn all steps into python functions,  </li>
<li>Create a class to host them. It facilitates the communication between the functions,  </li>
<li>Add the needed information as class instances items.<br>In the end it worked pretty well. The build was uneventful and I did what I set out to do. Could it be always like that.<br>The app is made from two modules, one that houses the class and does all the heavy lifting, the other, a lighter, simpler file, where you input data to build the instance that’ll become your scraper. I also call the functions from this file.<br>Regarding the class, the file is called ‘scraper.py’, and it’s built like this:<br>In the __init__ function of the class I define what will be the instances requisites.<br>The items are:  </li>
<li>Name: Name of the publication.</li>
<li>Project Name: Name for the project folder.I just use ‘name’ and prefix it with ‘_info’.  </li>
<li>Path: Path to your project.  </li>
<li>Beginning URLs: The pages that you want to scrape first.  </li>
<li>Content Title: The title that accompanies the news.  </li>
<li>Content Author: Who wrote the piece.  </li>
<li>Content Date Altered: When, if when, was the piece revised.  </li>
<li>Content: The text of the piece.  </li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, name, project_name, path, start_urls, title, author, date_altered, content</span>):</span></span><br><span class="line">     self.name = name</span><br><span class="line">     self.project_name = project_name</span><br><span class="line">     self.path = path</span><br><span class="line">     self.start_urls = start_urls</span><br><span class="line">     self.title = title</span><br><span class="line">     self.author = author</span><br><span class="line">     self.date_altered = date_altered</span><br><span class="line">     self.content = content</span><br></pre></td></tr></table></figure>
<p>First we have go to where we want to keep the projects. ‘os.chdir’ is a Python command to change the current working directory. os.mkdir creates a directory.  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dislocation1</span>(<span class="params">self</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;We head for designated local for the app and create a folder to house it&quot;&quot;&quot;</span></span><br><span class="line">    os.chdir(<span class="string">&quot;/home/mic/python/scraper&quot;</span>)</span><br><span class="line">    os.mkdir(<span class="string">f&quot;<span class="subst">&#123;self.project_name&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>The next step is to let Scrapy create the project folders and files. For that we are going to use a bash command which forces us to run it through Subprocess. The ‘cwd=path’ part, instructs Subprocess to execute it in the specified folder. While defining ‘path’ we use <a target="_blank" rel="noopener" href="https://www.geeksforgeeks.org/formatted-string-literals-f-strings-python/">f-Strings</a>, where we input an ‘f’ in the beginning of the string and envelop a variable name with ‘{}’ to represent their value.   </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">start_project</span>(<span class="params">self</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Scrapy command to start a project&quot;&quot;&quot;</span></span><br><span class="line">    path = <span class="string">f&quot;/home/mic/python/scraper/<span class="subst">&#123;self.project_name&#125;</span>&quot;</span></span><br><span class="line">    cmd = <span class="string">&quot;scrapy startproject &quot;</span> + self.name</span><br><span class="line">    subprocess.run(cmd, cwd=path, shell=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>It is now time to start building the spider. For that it’s needed to run another command-line, command. Because of this, the structure of the function is very similar to the former.  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">start_spider</span>(<span class="params">self</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Scrapy command to initiate a spider&quot;&quot;&quot;</span></span><br><span class="line">    project_name = self.project_name</span><br><span class="line">    name = self.name</span><br><span class="line">    paths = <span class="string">&quot;/home/mic/python/scraper/&quot;</span> + project_name + <span class="string">&quot;/&quot;</span> + name + <span class="string">&quot;/&quot;</span> + name + <span class="string">&quot;/spiders&quot;</span></span><br><span class="line">    cmd = <span class="string">f&quot;scrapy genspider <span class="subst">&#123;self.name&#125;</span>_info <span class="subst">&#123;self.start_urls&#125;</span>&quot;</span>  <span class="comment"># O nome tem de ser diferente do projecto.</span></span><br><span class="line">    subprocess.run(cmd, cwd=paths, shell=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>We now need to erase some text from the files and add a new one.<br>In this function will do only the erasing.<br>We will delete the string “http”, because when we put our URLs, it latches on to them and creates URLs with this format: “<a target="_blank" rel="noopener" href="http://https//new_url.com&quot;">http://https://new_url.com&quot;</a>.<br>In the text on the file, there’s a class that expects our input, as it only has “pass” as content. We’ll erase it. Because this implies changing a file, and files in Python are immutable, we need to take the following steps:  </p>
<ol>
<li>First we change current working directory to where the file is with os.chdir.  </li>
<li>We open it in ‘read’ mode, and create an output file to put the original text, plus the changes we want to make.  </li>
<li>We replace “http://“ with nothing.  </li>
<li>We replace “pass” with nothing.  </li>
<li>We write these changes on the output file.  </li>
<li>We remove the original file.  </li>
<li>We change the output file name to the name of the original file.  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">edit_spider_file_clean_file</span>(<span class="params">self</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Here we clean the spider file a bit. It comes a bit dirty when it is generated by Scrapy&quot;&quot;&quot;</span></span><br><span class="line">    os.chdir(<span class="string">f&quot;/<span class="subst">&#123;self.path&#125;</span>/<span class="subst">&#123;self.project_name&#125;</span>/<span class="subst">&#123;self.name&#125;</span>/<span class="subst">&#123;self.name&#125;</span>/spiders&quot;</span>)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">f&quot;<span class="subst">&#123;self.name&#125;</span>_info.py&quot;</span>, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> infile, <span class="built_in">open</span>(<span class="string">f&quot;<span class="subst">&#123;self.name&#125;</span>_output.py&quot;</span>, <span class="string">&quot;w&quot;</span>) <span class="keyword">as</span> outfile:</span><br><span class="line">        data = infile.read()</span><br><span class="line">        data = data.replace(<span class="string">&quot;http://&quot;</span>, <span class="string">&quot;&quot;</span>)</span><br><span class="line">        data = data.replace(<span class="string">&quot;pass&quot;</span>, <span class="string">&quot;&quot;</span>)</span><br><span class="line">        outfile.write(data)</span><br><span class="line">        os.remove(<span class="string">f&quot;<span class="subst">&#123;self.name&#125;</span>_info.py&quot;</span>)</span><br><span class="line">        cmd = <span class="string">f&quot;mv <span class="subst">&#123;self.name&#125;</span>_output.py <span class="subst">&#123;self.name&#125;</span>_info.py&quot;</span></span><br><span class="line">        subprocess.run(cmd, shell=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure></li>
</ol>
<p> Then we arrive to the trickiest function to write. We have to insert strings on a file, taking into account that they need to be in particular places on it. This was harder than I thought.<br> The first four changes pertain to <a target="_blank" rel="noopener" href="https://www.w3.org/TR/xpath20/">Xpath</a> commands, that’ll define what from where in the webpage we’ll be scraping.<br> They all take the form of variables and all have the suffix “response.xpath()”, that indicates that we’re seeing something collected from the scraping, the “response” part, encoded in Xpath. The browser’s developer tools lets us choose a CSS element and copy its Xpath address, making the job even easier than using CSS names. They will all be organized as a Python dictionary with the <a target="_blank" rel="noopener" href="https://www.w3schools.com/python/ref_func_zip.asp">zip</a> command. If it’s not a dictionary, XML, JSON and some other type of file I cannot remember right now, Scrapy won’t accept it.<br> We open the file in writing and execute the commands therein.  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">edit_spider_file_parse_function</span>(<span class="params">self</span>):</span></span><br><span class="line">       <span class="string">&quot;&quot;&quot;We add to the file information regarding the areas of the site we want to target&quot;&quot;&quot;</span></span><br><span class="line">       os.chdir(<span class="string">f&quot;/<span class="subst">&#123;self.path&#125;</span>/<span class="subst">&#123;self.project_name&#125;</span>/<span class="subst">&#123;self.name&#125;</span>/<span class="subst">&#123;self.name&#125;</span>/spiders&quot;</span>)</span><br><span class="line">       <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">f&quot;<span class="subst">&#123;self.name&#125;</span>_info.py&quot;</span>, <span class="string">&quot;a&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">           f.write(<span class="string">f&quot;        title = response.xpath(&#x27;<span class="subst">&#123;self.title&#125;</span>&#x27;).extract()&quot;</span> <span class="string">&quot;\n&quot;</span>)</span><br><span class="line">           f.write(<span class="string">f&quot;        author = response.xpath(&#x27;<span class="subst">&#123;self.author&#125;</span>&#x27;).extract()&quot;</span> <span class="string">&quot;\n&quot;</span>)</span><br><span class="line">           f.write(<span class="string">f&quot;        date_altered = response.xpath(&#x27;<span class="subst">&#123;self.date_altered&#125;</span>&#x27;).extract()&quot;</span> <span class="string">&quot;\n&quot;</span>)</span><br><span class="line">           f.write(<span class="string">f&quot;        content = response.xpath(&#x27;<span class="subst">&#123;self.content&#125;</span>&#x27;).getall()&quot;</span> <span class="string">&quot;\n&quot;</span>)</span><br><span class="line">           f.write(<span class="string">&quot;        data = zip(title, author, date_altered, content)&quot;</span>)</span><br><span class="line">           f.write(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line">           f.write(<span class="string">&quot;        for item in data:\n&quot;</span>)</span><br><span class="line">           f.write(</span><br><span class="line">               <span class="string">&quot;            info = &#123;&#x27;title&#x27;: i:wtem[0], &#x27;author&#x27;: item[1], &#x27;date_altered&#x27;: item[2], &#x27;content&#x27;: item[3]&#125;&quot;</span></span><br><span class="line">           )</span><br><span class="line">           f.write(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line">           f.write(<span class="string">&quot;        yield info&quot;</span>)</span><br><span class="line">           f.write(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line">           f.write(<span class="string">&quot;        with open(&#x27;content.txt&#x27;, &#x27;w&#x27;) as cont:&quot;</span>)</span><br><span class="line">           f.write(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line">           f.write(<span class="string">f&quot;            for i in response.xpath(&#x27;<span class="subst">&#123;self.content&#125;</span>&#x27;).getall():&quot;</span>)</span><br><span class="line">           f.write(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line">           f.write(<span class="string">&quot;                cont.write(str(i))&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>We now change folders with os.chdir(), to get to the settings.py file, and add two settings:  </p>
<ol>
<li>We define the feed format. ‘json’ in this case.  </li>
<li>The name of the file that will host the scraped information.  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">settings</span>(<span class="params">self</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;We add information regarding the format of the output&quot;&quot;&quot;</span></span><br><span class="line">    os.chdir(<span class="string">f&quot;<span class="subst">&#123;self.path&#125;</span>/<span class="subst">&#123;self.project_name&#125;</span>/<span class="subst">&#123;self.name&#125;</span>/<span class="subst">&#123;self.name&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;settings.py&quot;</span>, <span class="string">&quot;a&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(<span class="string">&#x27;FEED_FORMAT = &quot;json&quot;&#x27;</span>)</span><br><span class="line">        f.write(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line">        f.write(<span class="string">f&quot;FEED_URI = &#x27;<span class="subst">&#123;self.name&#125;</span>.json&#x27;&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Changes to settings are done&quot;</span>)</span><br></pre></td></tr></table></figure></li>
</ol>
<p>Now we start, finally, crawling the site. As it’s another command line command, we’ll be using Subprocess again.  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">crawl</span>(<span class="params">self</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;We initiate the scraping&quot;&quot;&quot;</span></span><br><span class="line">    path = self.path</span><br><span class="line">    project_name = self.project_name</span><br><span class="line">    name = self.name</span><br><span class="line">    path = path + <span class="string">&quot;/&quot;</span> + project_name + <span class="string">&quot;/&quot;</span> + name + <span class="string">&quot;/&quot;</span> + name + <span class="string">&quot;/spiders/&quot;</span></span><br><span class="line">    cmd = <span class="string">&quot;scrapy crawl &quot;</span> + name + <span class="string">&quot;_info&quot;</span></span><br><span class="line">    subprocess.run(cmd, cwd=path, shell=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>We now open the file created on the last step, and check if all was scraped correctly.  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">result</span>(<span class="params">self</span>):</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;Verifying the output file, to see if everything is OK&quot;&quot;&quot;</span></span><br><span class="line">    name = self.name</span><br><span class="line">    path = <span class="string">f&quot;<span class="subst">&#123;self.path&#125;</span>/<span class="subst">&#123;self.project_name&#125;</span>/<span class="subst">&#123;self.name&#125;</span>/<span class="subst">&#123;self.name&#125;</span>/spiders/&quot;</span></span><br><span class="line">    cmd = <span class="string">&quot;vim &quot;</span> + name + <span class="string">&quot;.json&quot;</span></span><br><span class="line">    subprocess.run(cmd, cwd=path, shell=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>Here is all the code:  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;The objective of this module is to automate the steps to scrape a given publication&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> subprocess</span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> loguru <span class="keyword">import</span> logger</span><br><span class="line"></span><br><span class="line">fmt = <span class="string">&quot;&#123;time&#125; - &#123;name&#125; - &#123;level&#125; - &#123;message&#125;&quot;</span></span><br><span class="line">logger.add(<span class="string">&quot;spam.log&quot;</span>, level=<span class="string">&quot;DEBUG&quot;</span>, <span class="built_in">format</span>=fmt)</span><br><span class="line">logger.add(<span class="string">&quot;error.log&quot;</span>, level=<span class="string">&quot;ERROR&quot;</span>, <span class="built_in">format</span>=fmt)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Scraper</span>:</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;This class will be broken in the steps needed to create a scraping campaign. Each step a function.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, name, project_name, path, start_urls, title, author, date_altered, content</span>):</span></span><br><span class="line">        self.name = name</span><br><span class="line">        self.project_name = project_name</span><br><span class="line">        self.path = path</span><br><span class="line">        self.start_urls = start_urls</span><br><span class="line">        self.title = title</span><br><span class="line">        self.author = author</span><br><span class="line">        self.date_altered = date_altered</span><br><span class="line">        self.content = content</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">dislocation1</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;We head for designated local for the app and create a folder to house it&quot;&quot;&quot;</span></span><br><span class="line">        os.chdir(<span class="string">&quot;/home/mic/python/scraper&quot;</span>)</span><br><span class="line">        os.mkdir(<span class="string">f&quot;<span class="subst">&#123;self.project_name&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start_project</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;Scrapy command to start a project&quot;&quot;&quot;</span></span><br><span class="line">        path = <span class="string">f&quot;/home/mic/python/scraper/<span class="subst">&#123;self.project_name&#125;</span>&quot;</span></span><br><span class="line">        cmd = <span class="string">&quot;scrapy startproject &quot;</span> + self.name</span><br><span class="line">        subprocess.run(cmd, cwd=path, shell=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start_spider</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;Scrapy command to initiate a spider&quot;&quot;&quot;</span></span><br><span class="line">        project_name = self.project_name</span><br><span class="line">        name = self.name</span><br><span class="line">        paths = <span class="string">&quot;/home/mic/python/scraper/&quot;</span> + project_name + <span class="string">&quot;/&quot;</span> + name + <span class="string">&quot;/&quot;</span> + name + <span class="string">&quot;/spiders&quot;</span></span><br><span class="line">        cmd = <span class="string">f&quot;scrapy genspider <span class="subst">&#123;self.name&#125;</span>_info <span class="subst">&#123;self.start_urls&#125;</span>&quot;</span>  <span class="comment"># O nome tem de ser diferente do projecto.</span></span><br><span class="line">        subprocess.run(cmd, cwd=paths, shell=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">edit_spider_file_clean_file</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;Here we clean the spider file a bit. It comes a bit dirty when it is generated by Scrapy&quot;&quot;&quot;</span></span><br><span class="line">        os.chdir(<span class="string">f&quot;/<span class="subst">&#123;self.path&#125;</span>/<span class="subst">&#123;self.project_name&#125;</span>/<span class="subst">&#123;self.name&#125;</span>/<span class="subst">&#123;self.name&#125;</span>/spiders&quot;</span>)</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">f&quot;<span class="subst">&#123;self.name&#125;</span>_info.py&quot;</span>, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> infile, <span class="built_in">open</span>(<span class="string">f&quot;<span class="subst">&#123;self.name&#125;</span>_output.py&quot;</span>, <span class="string">&quot;w&quot;</span>) <span class="keyword">as</span> outfile:</span><br><span class="line">            data = infile.read()</span><br><span class="line">            data = data.replace(<span class="string">&quot;http://&quot;</span>, <span class="string">&quot;&quot;</span>)</span><br><span class="line">            data = data.replace(<span class="string">&quot;pass&quot;</span>, <span class="string">&quot;&quot;</span>)</span><br><span class="line">            outfile.write(data)</span><br><span class="line">            os.remove(<span class="string">f&quot;<span class="subst">&#123;self.name&#125;</span>_info.py&quot;</span>)</span><br><span class="line">            cmd = <span class="string">f&quot;mv <span class="subst">&#123;self.name&#125;</span>_output.py <span class="subst">&#123;self.name&#125;</span>_info.py&quot;</span></span><br><span class="line">            subprocess.run(cmd, shell=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">edit_spider_file_parse_function</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;We add to the file information regarding the areas of the site we want to target&quot;&quot;&quot;</span></span><br><span class="line">        os.chdir(<span class="string">f&quot;/<span class="subst">&#123;self.path&#125;</span>/<span class="subst">&#123;self.project_name&#125;</span>/<span class="subst">&#123;self.name&#125;</span>/<span class="subst">&#123;self.name&#125;</span>/spiders&quot;</span>)</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">f&quot;<span class="subst">&#123;self.name&#125;</span>_info.py&quot;</span>, <span class="string">&quot;a&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(<span class="string">f&quot;        title = response.xpath(&#x27;<span class="subst">&#123;self.title&#125;</span>&#x27;).extract()&quot;</span> <span class="string">&quot;\n&quot;</span>)</span><br><span class="line">            f.write(<span class="string">f&quot;        author = response.xpath(&#x27;<span class="subst">&#123;self.author&#125;</span>&#x27;).extract()&quot;</span> <span class="string">&quot;\n&quot;</span>)</span><br><span class="line">            f.write(<span class="string">f&quot;        date_altered = response.xpath(&#x27;<span class="subst">&#123;self.date_altered&#125;</span>&#x27;).extract()&quot;</span> <span class="string">&quot;\n&quot;</span>)</span><br><span class="line">            f.write(<span class="string">f&quot;        content = response.xpath(&#x27;<span class="subst">&#123;self.content&#125;</span>&#x27;).getall()&quot;</span> <span class="string">&quot;\n&quot;</span>)</span><br><span class="line">            f.write(<span class="string">&quot;        data = zip(title, author, date_altered, content)&quot;</span>)</span><br><span class="line">            f.write(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line">            f.write(<span class="string">&quot;        for item in data:\n&quot;</span>)</span><br><span class="line">            f.write(</span><br><span class="line">                <span class="string">&quot;            info = &#123;&#x27;title&#x27;: i:wtem[0], &#x27;author&#x27;: item[1], &#x27;date_altered&#x27;: item[2], &#x27;content&#x27;: item[3]&#125;&quot;</span></span><br><span class="line">            )</span><br><span class="line">            f.write(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line">            f.write(<span class="string">&quot;        yield info&quot;</span>)</span><br><span class="line">            f.write(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line">            f.write(<span class="string">&quot;        with open(&#x27;content.txt&#x27;, &#x27;w&#x27;) as cont:&quot;</span>)</span><br><span class="line">            f.write(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line">            f.write(<span class="string">f&quot;            for i in response.xpath(&#x27;<span class="subst">&#123;self.content&#125;</span>&#x27;).getall():&quot;</span>)</span><br><span class="line">            f.write(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line">            f.write(<span class="string">&quot;                cont.write(str(i))&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">settings</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;We add information regarding the format of the output&quot;&quot;&quot;</span></span><br><span class="line">        os.chdir(<span class="string">f&quot;<span class="subst">&#123;self.path&#125;</span>/<span class="subst">&#123;self.project_name&#125;</span>/<span class="subst">&#123;self.name&#125;</span>/<span class="subst">&#123;self.name&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;settings.py&quot;</span>, <span class="string">&quot;a&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(<span class="string">&#x27;FEED_FORMAT = &quot;json&quot;&#x27;</span>)</span><br><span class="line">            f.write(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line">            f.write(<span class="string">f&quot;FEED_URI = &#x27;<span class="subst">&#123;self.name&#125;</span>.json&#x27;&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Changes to settings are done&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">crawl</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;We initiate the scraping&quot;&quot;&quot;</span></span><br><span class="line">        path = self.path</span><br><span class="line">        project_name = self.project_name</span><br><span class="line">        name = self.name</span><br><span class="line">        path = path + <span class="string">&quot;/&quot;</span> + project_name + <span class="string">&quot;/&quot;</span> + name + <span class="string">&quot;/&quot;</span> + name + <span class="string">&quot;/spiders/&quot;</span></span><br><span class="line">        cmd = <span class="string">&quot;scrapy crawl &quot;</span> + name + <span class="string">&quot;_info&quot;</span></span><br><span class="line">        subprocess.run(cmd, cwd=path, shell=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">result</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;Verifying the output file, to see if everythng is ok&quot;&quot;&quot;</span></span><br><span class="line">        name = self.name</span><br><span class="line">        path = <span class="string">f&quot;<span class="subst">&#123;self.path&#125;</span>/<span class="subst">&#123;self.project_name&#125;</span>/<span class="subst">&#123;self.name&#125;</span>/<span class="subst">&#123;self.name&#125;</span>/spiders/&quot;</span></span><br><span class="line">        cmd = <span class="string">&quot;vim &quot;</span> + name + <span class="string">&quot;.json&quot;</span></span><br><span class="line">        subprocess.run(cmd, cwd=path, shell=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<hr>
<h2><span id="the-main-function">The Main Function</span></h2><p>On another file named ‘main_scraper.py’, we define the instances arguments for the class we just saw.<br>The last thing to do is run sequentially the functions that were created, to create simple and fast spider bot.  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python3.9</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;Main module of the app. Where all functionalities are accessed from&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">import</span> questionary</span><br><span class="line"><span class="keyword">from</span> scraper <span class="keyword">import</span> Scraper</span><br><span class="line"><span class="keyword">from</span> loguru <span class="keyword">import</span> logger</span><br><span class="line"></span><br><span class="line">fmt = <span class="string">&quot;&#123;time&#125; - &#123;name&#125; - &#123;level&#125; - &#123;message&#125;&quot;</span></span><br><span class="line">logger.add(<span class="string">&quot;spam.log&quot;</span>, level=<span class="string">&quot;DEBUG&quot;</span>, <span class="built_in">format</span>=fmt)</span><br><span class="line">logger.add(<span class="string">&quot;error.log&quot;</span>, level=<span class="string">&quot;ERROR&quot;</span>, <span class="built_in">format</span>=fmt)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Here we start, sequentially, all the steps needed to create a scraping campaign.&quot;&quot;&quot;</span></span><br><span class="line">    rasoura = Scraper(</span><br><span class="line">        <span class="string">&quot;eco&quot;</span>,</span><br><span class="line">        <span class="string">&quot;eco_newspaper&quot;</span>,</span><br><span class="line">        <span class="string">&quot;/home/mic/python/scraper&quot;</span>,</span><br><span class="line">        <span class="string">&quot;https://eco.sapo.pt/2021/08/10/chineses-obrigam-loja-da-xiaomi-em-portugal-a-desistir-de-pagamentos-com-criptomoedas/&quot;</span>,</span><br><span class="line">        <span class="string">&#x27;//*[@id=&quot;post-878113&quot;]/div/div[1]/header/h1/text()&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;//*[@id=&quot;post-878113&quot;]/div/div[1]/header/div[2]/div/div[1]/ul/li[1]/a/text()&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;//*[@id=&quot;post-878113&quot;]/div/div[1]/header/div[2]/div/div[1]/ul/li[2]&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;//*[@id=&quot;post-878113&quot;]/div/div[1]/div[1]/p/text()&#x27;</span>,</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    rasoura.dislocation1()</span><br><span class="line">    rasoura.start_project()</span><br><span class="line">    rasoura.start_spider()</span><br><span class="line">    rasoura.edit_spider_file_clean_file()</span><br><span class="line">    rasoura.edit_spider_file_parse_function()</span><br><span class="line">    rasoura.settings()</span><br><span class="line">    rasoura.crawl()</span><br><span class="line">    rasoura.result()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">main()</span><br></pre></td></tr></table></figure>
</div></div><div class="footer"><div class="footer-copyright">Theme By <a target="_blank" rel="noopener" href="https://github.com/shinux/hexo-theme-adoubi">Adoubi</a> , Powered By Hexo.</div></div></body></html>